{"0": {
    "doc": "About",
    "title": "About",
    "content": "# MetaArchive In a Nut Shell MetaArchive uses the free open source LOCKSS archiving software to operate a network of preservation servers. Due to the low cost participation it is affordable for libraries of all sizes. LOCKSS is an ACM award winning digital preservation technology which preserves all formats and genres of web-published content from full fledged web sites to simple web hosted directories. Content is stored in and restored to its original format. Participating institutions identify valuable digital assets that they wish to preserve safely. They make the corresponding digital content accessible to MetaArchive network servers, so-called LOCKSS caches, which are configured to copy content, update it to its latest versions on a regular basis, and ensure its integrity over time. All content is stored in multiple copies on multiple caches at geographically dispersed locations. The MetaArchive network manages the number of replication so that a loss of all copies becomes extremely unlikely. If an institution loses preserved content for whatever reason its content is restored in its original form. Please find a Glossary of Terms at [Glossary](/glossary/). ## The Steps of Preservation with MetaArchive ### Phase 1: Preparing Content For some collections Content Preparation is very easy. In other cases some more effort may be necessary. For the more technically interested, Content Preparation covers content issues related to specific web server configurations and hosting scenarios. Ingest Procedures Overview provides an even more practical set-by-step walkthrough of the final stages of content preparation (plugin development, manifest pages, Conspectus entries, etc.). A general outline follows for the average reader. 1. A Content Owner identifies valuable digital content that needs to be safely preserved, for example: * electronic theses and dissertations * data sets * image masters * journals * other 2. The Content Owner prepares (or stages) content for preservation by: * making content accessible in a firewalled web hosted directory; * organizing content so that document files and metadata can be harvested together by LOCKSS caches; and * discussing with the MetaArchive central staff, when needed, how to harvest content files and METS/OAI metadata from a database backed institutional repository (ContentDM, DSPACE, homegrown, etc.) 3. The Content Owner prepares a collection description in the MetaArchive's Conspectus tool: * gives the collection a title and archive designation; * enters the source URL (base_url) for the web hosted directory (see above); and * provides some descriptive metadata for the collection 4. A Technical Person reviews the prepared (or staged) content, by: * planning the crawl procedure used by LOCKSS caches when ingesting/updating content; * tailors this procedure to the web site being crawled (i.e., defines Plugin crawl rules), for example: * defines rules to ignore links to ephemeral information such as 'Recent Announcements', 'Lastest News', etc.; and * defines rules to include all intended files (e.g., tiffs) but exclude all unintended files (e.g., low res jpgs) * planning how to organize contents so that LOCKSS caches archive big collections in manageable archival units (generally between 1GB-30GB) * making sure that the harvesting procedure will guide LOCKSS caches to copy all content needed to restore the collection in the event of total loss of the originals ### Phase 2: Configuring the MetaArchive Network to Ingest Content Phase 2 starts once the Content Owner and the Tech Person agree that the approach taken will preserve the intended content. This happens when: 1. The Tech Person publicizes the crawl procedure in the MetaArchive code repository; 2. The Tech Person and/or Content Owner enters configuration parameters for the content that is now available for preservation in the MetaArchive Conspectus tool; and 3. The MetaArchive Central Staff adds the configuration parameters to the MetaArchive title database ### Phase 3: Ingesting Content Ingest of the new content becomes possible once MetaArchive servers have noticed the new configuration settings. This happens when: 1. The MetaArchive Central Staff assigns the LOCKSS caches that are to preserve the new content; 1. Decisions are guided by the goal to replicate all content 7 times, thus seven caches are identified; 2. Chosen caches need to have sufficient disc space to store content; and 3. Caches chosen are geographically dispersed 2. A Tech Person at each assigned location adds the identified content to his/her caches configuration; and 3. The LOCKSS software starts to take care of the new content along with other preserved content. ### Phase 4: Preserving Content 1. The LOCKSS software running on each cache executes its processes on a routine schedule by: * harvesting content through the Internet from the url locations given in its configuration; * including all content that pass through the crawl rules defined for the collections; * initiating polls about the make up of preserved content with other LOCKSS caches in the network; * voting in polls initiated by peers; and * repairing content if a poll result shows convincingly that contents stored locally is inconsistent with the copies held by the majority of caches (memory failure can lead to such a situation) * helping other caches to repair content; 2. The MetaArchive Central Staff uses the Cache Manager and Conspectus tools to monitor the network status to insure that: * content is replicated sufficiently; and * the network operates correctly 3. The Content Owner revisits Phase 1 decisions and solutions whenever content structure changes; and 4. The Content Owner and Tech Person regularly audit content as it is preserved on caches to insure that the harvesting procedures put in place guide the LOCKSS caches correctly when ingesting and updating content (If not please go back to Phase 1, Step 4) ### Phase 5: Restoration of Content If the original data is lost: 1. The MetaArchive Central Staff helps the institution to identify caches where their content is replicated; and 2. The Tech Staff use the proxy feature of one of these caches to restore preserved content ",
    "url": "https://docs.blacktallman.com/about.html",
    "relUrl": "/about.html"
  },"1": {
    "doc": "Adding Plugins",
    "title": "Adding Plugins",
    "content": "How to add new plugins. ",
    "url": "https://docs.blacktallman.com/tutorials/members/addPlugin.html",
    "relUrl": "/tutorials/members/addPlugin.html"
  },"2": {
    "doc": "Cache Server",
    "title": "Cache Server",
    "content": "{: .text-delta } 1. TOC {:toc} Cache Daemon Release Notes -------------------------- LOCKSS periodically releases new Daemon versions. Some releases are pure bug fixes others include new features. Our [Daemon Release Notes](https://wiki.metaarchive.org/metawiki/index.php/CacheDaemon_ReleaseNotes) page summarizes the changes that are relevant to the MetaArchive network. Cache Purchasing ---------------- In order to keep the workloads as reasonable as possible at each member institution, the MetaArchive Cooperative makes a selection of one hardware configuration in October of each year, and supports the installation and maintenance of the network's software across all of the servers in the network that adopt that configuration. The current hardware Technical Specifications can be obtained [here](http://www.metaarchive.org/public/resources/charter_member/ma_2014technicalspecifications.pdf) Member institutions that choose to implement this hardware gain the assistance of the MetaArchive central staff and extended community in the installation, maintenance, and troubleshooting of their preservation server. This substantially decreases the burden of work on the local systems administrators at member sites. The MetaArchive identifies a vendor with the most competitive product that meets our current Technical Specifications. For new Member institutions that must provide additional documentation to their Office of Procurement to justify purchases from such vendors in the event they are not registered with their institution, the MetaArchive is providing a [Sole Source Checklist](http://www.metaarchive.org/public/resources/for_members/Sole_Source_Procurement.doc) to facilitate purchase from our preferred vendor. Cache Setup ----------- 1. The member institution provides an IP and domain name for the new cache. 2. MetaArchive staff makes sure the new cache has access to the MetaArchive configuration files 3. MetaArchive staff updates the IP lists used by web server administrators at member institutions to maintain firewall rules allowing the new cache to access memeber content. 4. MetaArchive Staff provides an ISO and install instructions [Cache Configuration](https://wiki.metaarchive.org/metawiki/index.php/Cache_Configuration) Cache Access, Ports, and Firewalls ---------------------------------- The LOCKSS daemon's web interface runs on port 8081. Caches communicate with each other by sending and receiving messages on port 9729. Caches provide port 8080 as a proxy port for preserved content, useful when content needs to be restored. Port 22 is used to ssh into a cache. For proper monitoring by the central staff port 8081 needs to be opened to administrative servers. For network communication to work smoothly administrators need to make sure that port 9729 of the caches under their supervision are open to all other cache IPs in the network. The relevant IP addresses are hosted at two urls. Detailed instructions about how to use these IP lists can be found in the README file at the bottom of the lists: 1. [admin.metaarchive.org/protected/network/ips](http://admin.metaarchive.org/protected/network/ips). Access to this list requires use of the relevant login/pass on our [Credentials](https://wiki.metaarchive.org/metawiki/index.php/Credentials) page. 2. [admin.metaarchive.org/network/ips/](http://admin.metaarchive.org/network/ips). Access to this list is open to all of the caches in the network. Cache Maintenance ----------------- Occasionally MetaArchive staff ask system administrators to perform local administration tasks. This happens infrequently. It usually involves executing specific command or scripts provided by MetaArchive staff. The commands needed to perform maintenance tasks are detailed in [CachesMaintain](https://wiki.metaarchive.org/metawiki/index.php/CachesMaintain) Cache Bandwidth --------------- - The bandwidth for the cache has two parts. - There is almost always a low amount of bandwidth being used for communications with the other caches. Short messages are constantly sent back and forth. A very busy cache might send and receive 300-400 Mbytes of data in a week in these messages. - The second part is when the cache needs to ingest content. This is generally a lot of bandwidth over short periods of time. Your cache might need to receive from a few GBytes of data, to hundreds of Gbytes over just a day or two. Right now this ingest happens maybe once or twice a month at most. - When it comes to bandwidth the peak usage comes when our members are having their own content ingested by the other caches in the network. But this is not an issue for your Lockss cache, it will be an issue for you content server. Cache Monitoring ---------------- Some of our members use Nagios to monitor their servers. A suggested configuration for metaarchive/LOCKSS caches can be found at [CacheNagios](https://wiki.metaarchive.org/metawiki/index.php/CacheNagios) ",
    "url": "https://docs.blacktallman.com/docs/lockss/cache-server.html",
    "relUrl": "/docs/lockss/cache-server.html"
  },"3": {
    "doc": "Conspectus",
    "title": "Conspectus",
    "content": "This page is about conspectus. ",
    "url": "https://docs.blacktallman.com/docs/conspectus.html",
    "relUrl": "/docs/conspectus.html"
  },"4": {
    "doc": "Restart All Daemons",
    "title": "Restart All Daemons",
    "content": "The daemon can make most configuration changes on the fly, but some configuration parameterss are only read at startup from the title database. It takes a restart to force existing AUs to start using an updated plugin. To cause all the daemons in your network to exit and restart, set org.lockss.app.exitOnce to true, wait twice the time defined in org.lockss.config.reloadInterval (or more) then set it back to false. Daemons exit when the see exitOnce transition from false to true. (If it's true when they start, they won't exit until it goes false, then true again.) Daemons check for prop changes approximately every reloadInterval - there's some randomization applied, so you have to wait longer than that interval to make sure all daemons have seen the change. Two times the interval is probably longer than necessary, but safe. ",
    "url": "https://docs.blacktallman.com/tutorials/staff/daemonForceRestart.html",
    "relUrl": "/tutorials/staff/daemonForceRestart.html"
  },"5": {
    "doc": "Glossary",
    "title": "Glossary",
    "content": "This page contains short definitions of LOCKSS/MetaArchive specific terms. Where appropiate we link to wikipedia for the definition of general technology terms for the less technical reader. Archive a subject or genre-based grouping of content (e.g., Southern Digital Culture, Electronic Theses and Dissertations) Archival Unit (AU) an independent collection of content in a LOCKSS cache. LOCKSS daemons create AUs by crawling a website using the AU's plugin and parameters. AUs are maintained by daemons as a unit via crawling, recrawling, polling and voting Cache or LOCKSS cache server running the LOCKSS daemon software which participates in a LOCKSS network Cache Manager A web based software tool which queries LOCKSS caches about their status and presents the information in a web based user interface. It incorporates command line report generators. CLOCKSS or Controlled LOCKSS, a community-governed partnership of libraries and publishers working to achieve a sustainable, globally-distributed archive, see http://www.clockss.org/clockss Conspectus A web based tool developed for the NDIIPP MetaArchive project that maintains information about collections preserved in the network along with LOCKSS specific collection configuration settings. Crawl Rules Plugins contain crawl rules which define which URLs encountered in a daemon's web crawl are ingested/copied by the local disk of the daemons cache. Ingest(ing) LOCKSS daemons ingest/copy content from URLs when they crawl content with the help of a plugin. Content is copied as it is retrieved from content servers via http gets. Daemons do not encrypt or compress copied content. LOCKSS daemon A daemon executing the LOCKSS software usually on a dedicated LOCKSS cache Library Cache Auditing Protocol (LCAP) A very slow-acting network communication protocol used by LOCKSS daemons to communicate with each other in Votes and Polls. LOCKSS LOCKSS (Lots Of Copies Keep Stuff Safe) is an open source, peer-to-peer, decentralized digital preservation infrastructure, see http://www.lockss.org/lockss LOCKSS network A network of LOCKSS caches that are maintained with a common title database Manifest Page The LOCKSS Crawler requests explicit permission to harvest content which it locates in so called manifest pages, see http://www.lockss.org/lockss/Publisher_Manifest_Page MetaArchive The Private LOCKSS Network that is behind this wiki. Network The Cooperative's community of LOCKSS caches Plugin A small XML file that instructs the LOCKSS software how to crawl, in terms of defining a starting URL, where to look for Manifest Pages, and how to decide which URLs to ingest/copy from the content providing web site Plugin Identifier JAVA style identifier, eg org.lockss.ingest, that identifies a plugin uniquely in a LOCKSS network Plugin Name short descriptive name for your plugin Plugin Repository LOCKSS daemons are configured to read plugin definitions from a web accessible plugin repositories. Plugins are deployed to plugin repositories as signed and jared files. PluginTool Java application that simplifies the creation of new LOCKSS plugins, see http://www.lockss.org/lockss/Plugin_Tool ",
    "url": "https://docs.blacktallman.com/glossary.html",
    "relUrl": "/glossary.html"
  },"6": {
    "doc": "Home",
    "title": "Home",
    "content": "This is a docs sandbox. ",
    "url": "https://docs.blacktallman.com/",
    "relUrl": "/"
  },"7": {
    "doc": "LOCKSS",
    "title": "LOCKSS",
    "content": "This page is about LOCKSS. ",
    "url": "https://docs.blacktallman.com/docs/lockss.html",
    "relUrl": "/docs/lockss.html"
  },"8": {
    "doc": "Member Tutorials",
    "title": "Member Tutorials",
    "content": "### For All Roles - [MetaArchive Ingest Procedures Overview](https://wiki.metaarchive.org/metawiki/index.php/MetaArchive_Ingest_Procedures_Overview) ### For Plugin Developers (for more info see [Plugins](https://wiki.metaarchive.org/metawiki/index.php/Plugins)) - [How to Download and Open Plugin Tool on Linux Platforms](http://www.lockss.org/locksswiki/index.php/Plugin_Tool) - [How to Download and Open Plugin Tool on Apple Platforms](https://wiki.metaarchive.org/metawiki/index.php/HowToOpenPluginOnMac) - [Getting Started with BagIt for MetaArchive](https://wiki.metaarchive.org/metawiki/index.php/Getting_Started_with_BagIt_for_MetaArchive) ### For Cache Administrators (for more info see [Caches](https://wiki.metaarchive.org/metawiki/index.php/Caches)) - [How to Configure the LOCKSS Daemon on a Cache](https://wiki.metaarchive.org/metawiki/index.php/HowToConfigureLockss) - [How to Gain Access to the LOCKSS Daemon User Interface](https://wiki.metaarchive.org/metawiki/index.php/HowToGetAccessToUI) - [How to Add Archival Units (AUs) to your LOCKSS Servers Configuration](https://wiki.metaarchive.org/metawiki/index.php/HowToAddAus) - [How to Ingest New AUs with a New Plugin](https://wiki.metaarchive.org/metawiki/index.php/HowToIngestAUsWithNewPlugin) - [How to View the CrawlStatus of an AU](https://wiki.metaarchive.org/metawiki/index.php/HowToViewAUCrawlStatus) - [How to Deactivate an AU](https://wiki.metaarchive.org/metawiki/index.php/HowToInactivateAU) - [How to Delete an AU](https://wiki.metaarchive.org/metawiki/index.php/HowToDeletaAU) - [How to Remove Files of Deleted AUs](https://wiki.metaarchive.org/metawiki/index.php/HowToRemoveCachedFiles) - [How to Find Archival Units with Fetch Errors](https://wiki.metaarchive.org/metawiki/index.php/HowToFindAusWithFetchErrors) - [How to Diagnose a Fetch Error](https://wiki.metaarchive.org/metawiki/index.php/HowToFetchError) - [How to Tell Daemons to Stop Harvesting an Archival Unit's Content from the Web](https://wiki.metaarchive.org/metawiki/index.php/HowToStopHarvestingForAUs) - [How to Speed Up Data Recovery after a Crash](https://wiki.metaarchive.org/metawiki/index.php/HowToSpeedUpDataRecovery) ### For Collection Managers - [How to Gain Access to the LOCKSS Daemon User Interface](https://wiki.metaarchive.org/metawiki/index.php/HowToGetAccessToUI) - [How to View the Content of an AU](https://wiki.metaarchive.org/metawiki/index.php/HowToViewAUContent) - [How to Enable the Audit Proxy of an AU](https://wiki.metaarchive.org/metawiki/index.php/HowToAuditProxyAUContent) - [How to Import the AU Sizes from the Cache Manager into Excel](https://wiki.metaarchive.org/metawiki/index.php/HowToImportAUSizesToExcelFromCacheManager) - [How to Retrieve Cache UI Tables in text,xml, and csv formats](https://wiki.metaarchive.org/metawiki/index.php/HowToRetrieveFormattedCacheTables) ",
    "url": "https://docs.blacktallman.com/tutorials/members.html",
    "relUrl": "/tutorials/members.html"
  },"9": {
    "doc": "Plugins",
    "title": "Plugins",
    "content": "Plugins play a central role in any LOCKSS network. They guide LOCKSS daemons in their decisions as to which file urls to fetch and preserve when they crawl provider web sites. Writing Plugins can be easy or time-intensive depending on a developer's familiarity with things like regular expressions and various web and browser technologies. In any case it is vital for the successful preservation of content to make sure plugins are properly written and tested. The MetaArchive project has developed practices, standards, and best practices along with documentation to help plugin developers. ### For Beginners The following links provide a set of documentation for developers to begin educating themselves and preparing for their plugin development: - [General Overview of Digital Preservation with MetaArchive](https://wiki.metaarchive.org/metawiki/index.php/DDPwithMetaArchive) - [Introduction to Plugins](http://www.lockss.org/locksswiki/index.php/Plugins), [Plugin Tool](http://www.lockss.org/locksswiki/index.php/Plugin_Tool), and [Plugin Tool Tutorial](http://www.lockss.org/locksswiki/index.php/Plugin_Tool_Tutorial) from the LOCKSS wiki - [Relationships explained: Plugins, LOCKSS daemons, Archival Units, Manifest Pages, and Harvesting Choices](https://wiki.metaarchive.org/metawiki/index.php/PluginHowItWorks) ### Plugin Developers The following links provide a set of documentation to help guide developers through the process of writing and preparing plugins for their collections: - [MetaArchive Ingest Procedures Overview](https://wiki.metaarchive.org/metawiki/index.php/MetaArchive_Ingest_Procedures_Overview) - [Making Use of Subversion](https://wiki.metaarchive.org/metawiki/index.php/Subversion) - [Getting Started with BagIt for MetaArchive](https://wiki.metaarchive.org/metawiki/index.php/Getting_Started_with_BagIt_for_MetaArchive) - [Plugin Development Cycle ](https://wiki.metaarchive.org/metawiki/index.php/PluginDevelopmentCycle)| [Test Cache Access](https://wiki.metaarchive.org/metawiki/index.php/TestCacheAccess) - [Plugin/Manifest Standards and Recommendation](https://wiki.metaarchive.org/metawiki/index.php/PluginStandards) - [Learn By Example ](https://wiki.metaarchive.org/metawiki/index.php/PluginSandbox)and [HowToProtectProprietaryContent](https://wiki.metaarchive.org/metawiki/index.php/HowToProtectProprietaryContent) - [The Plugin Xml format ](https://wiki.metaarchive.org/metawiki/index.php/PluginXmlFormat)(advanced developers) ### All Plugin Pages - [Plugins at Virginia Tech](https://wiki.metaarchive.org/metawiki/index.php/PluginsAtVirginiaTech) - [CONTENTdm Plugin Examples](https://wiki.metaarchive.org/metawiki/index.php/CONTENTdm_Plugin_Examples) - [PluginDaemonCrawlProcedure](https://wiki.metaarchive.org/metawiki/index.php/PluginDaemonCrawlProcedure) - [PluginDevelopmentCycle](https://wiki.metaarchive.org/metawiki/index.php/PluginDevelopmentCycle) - [PluginHowItWorks](https://wiki.metaarchive.org/metawiki/index.php/PluginHowItWorks) - [PluginSandbox or Learn By Example](https://wiki.metaarchive.org/metawiki/index.php/PluginSandbox) - [PluginsAtVirginiaTech](https://wiki.metaarchive.org/metawiki/index.php/PluginsAtVirginiaTech) - [PluginsResources](https://wiki.metaarchive.org/metawiki/index.php/PluginsResources) - [PluginStandards](https://wiki.metaarchive.org/metawiki/index.php/PluginStandards) - [PluginToolDaemonDifferences](https://wiki.metaarchive.org/metawiki/index.php/PluginToolDaemonDifferences) - [PluginWhyDoServersNotSeeMe](https://wiki.metaarchive.org/metawiki/index.php/PluginWhyDoServersNotSeeMe) - [PluginXmlFormat](https://wiki.metaarchive.org/metawiki/index.php/PluginXmlFormat) ",
    "url": "https://docs.blacktallman.com/docs/lockss/plugins.html",
    "relUrl": "/docs/lockss/plugins.html"
  },"10": {
    "doc": "Production Network",
    "title": "Production Network",
    "content": "This page is about the LOCKSS production network. ",
    "url": "https://docs.blacktallman.com/docs/lockss/prod-network.html",
    "relUrl": "/docs/lockss/prod-network.html"
  },"11": {
    "doc": "Staff Tutorials",
    "title": "Staff Tutorials",
    "content": "### For MetaArchive Central Staff - [How to Force All Daemons to Restart](https://wiki.metaarchive.org/metawiki/index.php/HowToRestartAllDaemons) - [How to Speed Up Data Recovery after a Crash](https://wiki.metaarchive.org/metawiki/index.php/HowToSpeedUpDataRecovery) - [How To Proxy Content between Two LOCKSS caches](https://wiki.metaarchive.org/metawiki/index.php/HowToProxyContent) - [How to Remove a Plugin from a LOCKSS Network](https://wiki.metaarchive.org/metawiki/index.php/HowToRemoveAPlugin) - [How to Investigate when a network produces many No Quorum Errors](https://wiki.metaarchive.org/metawiki/index.php/HowToInvestigateNoQuorum) - [How to Use Wireshark as a packet sniffer - And detect SSL is being used](https://wiki.metaarchive.org/metawiki/index.php/HowToCheckNetworkPackets) - [How to Create a Virtual PC for the test Network](https://wiki.metaarchive.org/metawiki/index.php/HowToBuildVirtBoxPC) - [How to Create a Cloud Computer in Amazon EC2 for the Properties Server](https://wiki.metaarchive.org/metawiki/index.php/HowToCloudComputing) - [How to Manage MA controlled Hostnames](https://wiki.metaarchive.org/metawiki/index.php/HowToCustomHostNames) ",
    "url": "https://docs.blacktallman.com/tutorials/staff.html",
    "relUrl": "/tutorials/staff.html"
  },"12": {
    "doc": "Staging Server",
    "title": "Staging Server",
    "content": "{: .text-delta } 1. TOC {:toc} # Maintaining Firewalls of Web Servers that host content preserved in MetaArchive System administrators maintaining servers that host content preserved in the MetaArchive network are expected to keep firewalls around preserved content open to MetaArchive. The relevant IP addresses are hosted at two urls. Detailed instructions about how to use these IP lists can be found in the README file at the bottom of the lists: - admin.metaarchive.org/protected/network/ips. Access to this list requires use of the relevant login/pass on our Credentials page. - admin.metaarchive.org/network/ips/. Access to this list is open to all of the caches in the network. MetaArchive staff alerts member institutions via an email whenever firewalls need to be updated. # Keeping Load on Web Servers Low When a LOCKSS daemon crawls a site, it skips downloading a file, if it can determine that the file on the web server is not younger than the file the daemon maintains on the local disk. Daemons use If-Modified-Since if the page previously fetched was served with a Last-Modified Date. Thus if you configure your sites to serve 'Last-Modified;' information out in http headers LOCKSS daemons put less load on your servers. If you preserve a site that LOCKSS crawls frequently and thoroughly you get a big payoff (and so will the network) if you configure your server/site to serve Last-Modified information. Even if your site generates content dynamically, it is helpful if you can at least serve Last-Modified info for documents, ie images, pdfs, ... To turn Last-Modified on in an Apache server do `IndexOptions TrackModified`. # Excluding LOCKSS Traffic from Web Statistics The LOCKSS wiki has information on how LOCKSS caches identify themselves when they interact with your web site, which you can use to exclude traffic generated by LOCKSS caches from traffic statistics. Please refer to LOCKSS Compliance/Statistics ",
    "url": "https://docs.blacktallman.com/docs/lockss/staging-server.html",
    "relUrl": "/docs/lockss/staging-server.html"
  },"13": {
    "doc": "Test Network",
    "title": "Test Network",
    "content": "{: .text-delta } 1. TOC {:toc} ### Active Test Caches The active test caches, the amount of space on their disks, and the content they currently maintain are available at - Access a cache by clicking on the link in the Hostname/Admin column ### Logging into a Test Cache Members need to request that the IP address of their desktop be added to the Admin Access List of test caches.\\ Please contact the [MetaArchive Staff](https://wiki.metaarchive.org/metawiki/index.php/User:Staff) The Login Credentials are listed at [Credentials](https://wiki.metaarchive.org/metawiki/index.php/Credentials) ### Locating Content in the Test Network To find the status of archival units that use a particular plugin (plugin prefix) use [archival units list](http://tstmonitor.metaarchive.org/archival_units/list) and enter a (partial) plugin name (replace '.' by '|') and choose 'All' instead of the default 'Problem' list mode. Alternatively use [archival unit lookup](http://tstmonitor.metaarchive.org/archival_units/status) and enter the desired values for plugin names, base_urls, or other parameters. Archival units that are part of the [DOC](http://metaarchive.org/conspectoy/archives/find/DOC) archive in the ConspecToy can be listed by looking for all archival units with a plugin prefix of 'doc.plugins'. ### Viewing the Status of an Archival Unit - To find which cache preserves a copy of a particular archival units, click on [archival units](http://tstmonitor.metaarchive.org/archival_units/list) in the top row menu and enter - (part of) the collection title the archival unit belongs to - one of the paramter values used by the archival unit - or (part of) the plugin name, with '.' replaced by '|' [HowToViewAUContent](https://wiki.metaarchive.org/metawiki/index.php/HowToViewAUContent) and [HowToViewAUCrawlStatus](https://wiki.metaarchive.org/metawiki/index.php/HowToViewAUCrawlStatus) explain how to view the status details of an archival unit in the LOCKSS DAemon User interface. ### Test Cache Configuration All Caches in the test network are configured as follows: - Title Database:  - the Title Database contains all archival units that are marked test or retest in the Conspectus; as well as - selected archival units from the [DOC](http://metaarchive.org/conspectoy/archives/find/DOC) archive in the Conspectus - Plugin Repository:  - jar files are regenerated by a cronjob which updates xml files to the latest version that was committed to the trunk of the MetaArchive Subversion Repository - the plugin jar files show their modification dates at the url above, so that plugin developers can check whether a jar file has in fact been updated since a change to its xml was committed -  contains a trace of the script that updates a plugin and jars them for the test network -  contains the currently known test plugins The title database, plugin jar, and xml files are all updated every 15 min. Test caches update their configurations every 15 min as well, so that in the worst case it takes 30 min for a new plugin or archival unit to be known to a daemon on a LOCKSS test cache. The update script for plugins logs its actions at [lockss_test/plugins/update_log](http://admin.metaarchive.org/lockss_test/plugins/update_log) ### Pushing an AU into the Test Network Please keep in mind that LOCKSS caches can ONLY understand an archival unit if: - it is part of the Title Database; and - its plugin is properly configured/updated in the Plugin Repository Only Archival Units whose status is marked as test or retest in the Conspectus (see [ConspectusHowTo](https://wiki.metaarchive.org/metawiki/index.php/ConspectusHowTo)) become part of the Title Database. Only plugins that are maintained in the trunk of the MetaArchive Subversion Repository are made available, see [Subversion info](https://wiki.metaarchive.org/metawiki/index.php/Subversion). You can see the latest Title Database at the link above. To actually add the AUs to a cache, see [How to add AUs](https://wiki.metaarchive.org/metawiki/index.php/HowToAddAus). ",
    "url": "https://docs.blacktallman.com/docs/lockss/test-network.html",
    "relUrl": "/docs/lockss/test-network.html"
  },"14": {
    "doc": "Tutorials",
    "title": "Tutorials",
    "content": " ",
    "url": "https://docs.blacktallman.com/tutorials.html",
    "relUrl": "/tutorials.html"
  }
}
